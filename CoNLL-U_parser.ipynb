{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the `.conllu` file line by lines\n",
    "`records` be an empty list of lists to hold tagged information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filnum_to_yearlocation = { \n",
    "    2: [\"יפו\", [1904,1904] ],\n",
    "    3: [\"יפו\",[1908,1908]],\n",
    "    4: [\"יפו\",[1903,1904]],\n",
    "    5: [\"יפו\",[1908,1908]],\n",
    "    6: [\"בויסק\",[1903,1903]],\n",
    "    7: [\"יפו\",[1908,1908]],\n",
    "    8: [\"ירושלים\",[1932,1932]],\n",
    "    9: [\"יפו\",[1910,1911]],\n",
    "    10: [\"יפו\",[1909,1911]],\n",
    "    11: [\"יפו\",[1911,1913]],\n",
    "    12: [\"יפו\",[1913,1913]],\n",
    "    13: [\"שוייץ\",[1913,1915]],\n",
    "    14: [\"שוייץ\",[1913,1915]],\n",
    "    15: [\"שוייץ\",[1913,1915]],\n",
    "    16: [\"לונדון\",[1915,1918]],\n",
    "}\n",
    "\n",
    "dataframe_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over a folder of .coNLLu files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#assume file format is [number]_[somename].txt\n",
    "directory = 'C:/Users/edens/OneDrive/Desktop/hebpipe/'\n",
    "records = list()\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(directory+filename, 'r', encoding='utf-8') as file:\n",
    "            file_prefix = filename.split('.')[0] + '_'\n",
    "            filenum= filename.split('_')[0]\n",
    "            doc_id = ''\n",
    "            sent_id = ''\n",
    "            records = list()\n",
    "            for line in file:\n",
    "                if len(line) > 1 :\n",
    "                    if line[0] == '#':\n",
    "                        line = line.split('=')\n",
    "                        if 'newdoc' in line[0]:\n",
    "                            doc_id = file_prefix + line[1].strip()\n",
    "                        elif 'sent_id' in line[0]:\n",
    "                            sent_id = line[1].strip()\n",
    "                    else:\n",
    "                        info = line.split('\\t')\n",
    "                        if len(info) == 10:\n",
    "                            records.append([doc_id, sent_id] + [x.strip() for x in info])\n",
    "        print(filenum)\n",
    "\n",
    "        #put in dataframe dictionary\n",
    "        dataframe_dict[filenum] = pd.DataFrame(records, columns=['DOC_ID', 'SENT_ID', 'ID', 'FORM','LEMMA','UPOS', 'XPOS', 'FEAT','HEAD', 'DEPREL', 'DEPS', 'MISC'])\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating file: 10\n",
      "done!\n",
      "creating file: 11\n",
      "done!\n",
      "creating file: 12\n",
      "done!\n",
      "creating file: 13\n",
      "done!\n",
      "creating file: 14\n",
      "done!\n",
      "creating file: 15\n",
      "done!\n",
      "creating file: 16\n",
      "done!\n",
      "creating file: 1\n",
      "done!\n",
      "creating file: 2\n",
      "done!\n",
      "creating file: 3\n",
      "done!\n",
      "creating file: 4\n",
      "done!\n",
      "creating file: 5\n",
      "done!\n",
      "creating file: 6\n",
      "done!\n",
      "creating file: 7\n",
      "done!\n",
      "creating file: 8\n",
      "done!\n",
      "creating file: 9\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#clean the dataframes\n",
    "\n",
    "for key in dataframe_dict :\n",
    "    print('creating file:' , key)\n",
    "    df = dataframe_dict[key]\n",
    "    df = df.drop(['DOC_ID','SENT_ID'], axis = 1)\n",
    "    if key != '1':\n",
    "        df['LOCATION'] = filnum_to_yearlocation[int(filenum)][0]\n",
    "        df['YEARS'] = pd.Interval(filnum_to_yearlocation[int(filenum)][1][0],filnum_to_yearlocation[int(filenum)][1][1],closed='both')\n",
    "    df[~df.ID.str.contains('-')].to_csv(key+'.csv', header=True, index=None, sep='\\t')\n",
    "    print('done!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e100f59cb0f9b35329e9945f9adbf0bae8463f636b852ff35428b09152b889bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
